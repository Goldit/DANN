{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "from random import shuffle\n",
    "from flip_gradient import flip_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset_path       = \"toppad/\"\n",
    "source_file        = 'source.txt'\n",
    "target_file        = 'target.txt'\n",
    "test_file          = 'test.txt'\n",
    "val_file           = 'val.txt'\n",
    "\n",
    "test_set_size      = 100\n",
    "\n",
    "NUM_CHANNELS       = 3\n",
    "BATCH_SIZE         = 32\n",
    "IMAGE_SIZE         = 256\n",
    "NUM_CLASSES        = 2\n",
    "NUM_DOMAINES       = 2\n",
    "IMG_SIZE_CROPPED   = 224\n",
    "LEARNING_RATE      = 0.001\n",
    "DATASET_SIZE       = 40000\n",
    "STEPS_PER_EPOCH    = int(DATASET_SIZE/BATCH_SIZE)\n",
    "OPTIMIZER          = 'Adam'\n",
    "MODEL_NAME         = 'dann'\n",
    "LAMBDA             = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "  return int(label)\n",
    "\n",
    "def encode_size(size):\n",
    "    w,h = size.split(\"x\")\n",
    "    return (int(w), int(h))\n",
    "\n",
    "def read_image_list(file):\n",
    "  f = open(file, \"r\")\n",
    "  filepaths = []\n",
    "  labels = []\n",
    "  for line in f:\n",
    "    filepath, label, size = line.split(\" \")\n",
    "    filepaths.append(dataset_path + filepath)\n",
    "    labels.append(encode_label(label))\n",
    "  return filepaths, labels\n",
    "\n",
    "def read_images(input_queue):\n",
    "    file_content = tf.read_file(input_queue[0])\n",
    "    image = tf.image.decode_jpeg(file_content, channels=NUM_CHANNELS)\n",
    "    image.set_shape([IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS])\n",
    "    label = input_queue[1]  \n",
    "    return image, label\n",
    "\n",
    "def pre_process_image(image, training):\n",
    "    # This function takes a single image as input,\n",
    "    # and a boolean whether to build the training or testing graph.\n",
    "    # vgg mean\n",
    "    mean = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32, shape=[1, 1, 3], name='img_mean')\n",
    "    image = image - mean\n",
    "    if training:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Randomly crop the input image.\n",
    "        image = tf.random_crop(image, size=[IMG_SIZE_CROPPED, IMG_SIZE_CROPPED, NUM_CHANNELS])\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "        # Randomly adjust hue, contrast and saturation.\n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "\n",
    "        # Some of these functions may overflow and result in pixel\n",
    "        # values beyond the [0, 1] range. It is unclear from the\n",
    "        # documentation of TensorFlow 0.10.0rc0 whether this is\n",
    "        # intended. A simple solution is to limit the range.\n",
    "\n",
    "        # Limit the image pixels between [0, 1] in case of overflow.\n",
    "        # image = tf.minimum(image, 1.0)\n",
    "        # image = tf.maximum(image, 0.0)\n",
    "    else:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Crop the input image around the centre so it is the same\n",
    "        # size as images that are randomly cropped during training.\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image,\n",
    "                                                       target_height=IMG_SIZE_CROPPED,\n",
    "                                                       target_width=IMG_SIZE_CROPPED)\n",
    "\n",
    "    return image\n",
    "\n",
    "source_images, source_labels = read_image_list(dataset_path + source_file)\n",
    "target_images, target_labels = read_image_list(dataset_path + target_file)\n",
    "test_images, test_labels = read_image_list(dataset_path + test_file)\n",
    "val_images, val_labels = read_image_list(dataset_path + val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_vgg_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"images\"], [-1, IMG_SIZE_CROPPED, IMG_SIZE_CROPPED, NUM_CHANNELS], name=\"input_layer\")\n",
    "\n",
    "    # Convolutional Layer #1_1\n",
    "    conv1_1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=64,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv1_1\")\n",
    "    # Convolutional Layer #1_2\n",
    "    conv1_2 = tf.layers.conv2d(\n",
    "      inputs=conv1_1,\n",
    "      filters=64,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv1_2\")\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1_2, pool_size=[2, 2], strides=2, name=\"pool1\")\n",
    "\n",
    "    # Convolutional Layer #2_1\n",
    "    conv2_1 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=128,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv2_1\")\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2_2 = tf.layers.conv2d(\n",
    "      inputs=conv2_1,\n",
    "      filters=128,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv2_2\")\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2_2, pool_size=[2, 2], strides=2, name=\"pool2\")\n",
    "\n",
    "    # Convolutional Layer #3_1\n",
    "    conv3_1 = tf.layers.conv2d(\n",
    "      inputs=pool2,\n",
    "      filters=256,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv3_1\")\n",
    "\n",
    "    # Convolutional Layer #3_1\n",
    "    conv3_2 = tf.layers.conv2d(\n",
    "      inputs=conv3_1,\n",
    "      filters=256,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv3_2\")\n",
    "\n",
    "    # Convolutional Layer #3_1\n",
    "    conv3_3 = tf.layers.conv2d(\n",
    "      inputs=conv3_2,\n",
    "      filters=256,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv3_3\")\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3_3, pool_size=[2, 2], strides=2, name=\"pool3\")    \n",
    "\n",
    "    # Convolutional Layer #4_1\n",
    "    conv4_1 = tf.layers.conv2d(\n",
    "      inputs=pool3,\n",
    "      filters=512,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv4_1\")\n",
    "\n",
    "    # Convolutional Layer #4_2\n",
    "    conv4_2 = tf.layers.conv2d(\n",
    "      inputs=conv4_1,\n",
    "      filters=512,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv4_2\")\n",
    "\n",
    "    # Convolutional Layer #4_3\n",
    "    conv4_3 = tf.layers.conv2d(\n",
    "      inputs=conv4_2,\n",
    "      filters=512,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv4_3\")\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4_3, pool_size=[2, 2], strides=2, name=\"pool4\")\n",
    "\n",
    "    # Convolutional Layer #5_1\n",
    "    conv5_1 = tf.layers.conv2d(\n",
    "      inputs=pool4,\n",
    "      filters=512,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv5_1\")\n",
    "\n",
    "    # Convolutional Layer #5_2\n",
    "    conv5_2 = tf.layers.conv2d(\n",
    "      inputs=conv5_1,\n",
    "      filters=512,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv5_2\")\n",
    "\n",
    "    # Convolutional Layer #5_3\n",
    "    conv5_3 = tf.layers.conv2d(\n",
    "      inputs=conv5_2,\n",
    "      filters=512,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      name=\"conv5_3\")\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5_3, pool_size=[2, 2], strides=2, name=\"pool5\")\n",
    "\n",
    "    # FC Layers\n",
    "    all_features =tf.contrib.layers.flatten(pool5)\n",
    "    with tf.name_scope('extract_lb_feat'):\n",
    "        source_features =  tf.strided_slice(all_features, [0], [tf.to_int32(all_features.shape[0])], [2])\n",
    "        classify_feats = tf.cond(tf.cast(mode == learn.ModeKeys.TRAIN, tf.bool), lambda:source_features, lambda:all_features)\n",
    "    lb_fc1   = tf.layers.dense(inputs=classify_feats, units=4096, activation=tf.nn.relu, name=\"lb_fc1\")\n",
    "    lb_dropout1 = tf.layers.dropout(inputs=lb_fc1, rate=0.5, training=mode==learn.ModeKeys.TRAIN, name=\"lb_dropout1\")\n",
    "    lb_fc2   = tf.layers.dense(inputs=lb_dropout1, units=4096, activation=tf.nn.relu, name=\"lb_fc2\")\n",
    "    lb_dropout2 = tf.layers.dropout(inputs=lb_fc2, rate=0.5, training=mode==learn.ModeKeys.TRAIN, name=\"lb_dropout2\")\n",
    "    label_logits = tf.layers.dense(inputs=lb_dropout2, units=NUM_CLASSES, name=\"lb_softmax\")\n",
    "\n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        with tf.name_scope('flip_gradient'):\n",
    "            flipped_features = flip_gradient(all_features)\n",
    "        dm_fc1   = tf.layers.dense(inputs=flipped_features, units=4096, activation=tf.nn.relu, name=\"dm_fc1\")\n",
    "        dm_dropout1 = tf.layers.dropout(inputs=dm_fc1, rate=0.5, training=mode==learn.ModeKeys.TRAIN, name=\"dm_dropout1\")\n",
    "        dm_fc2   = tf.layers.dense(inputs=dm_dropout1, units=4096, activation=tf.nn.relu, name=\"dm_fc2\")\n",
    "        dm_dropout2 = tf.layers.dropout(inputs=dm_fc2, rate=0.5, training=mode==learn.ModeKeys.TRAIN, name=\"dm_dropout2\")\n",
    "        domain_logits = tf.layers.dense(inputs=dm_dropout2, units=NUM_DOMAINES, name=\"dm_softmax\")\n",
    "\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    \n",
    "    if mode != learn.ModeKeys.INFER:\n",
    "        with tf.name_scope('label_loss'):\n",
    "            source_labels = tf.strided_slice(labels, [0], [tf.to_int32(labels.shape[0])], [2])\n",
    "            classify_labels = tf.cond(tf.cast(mode == learn.ModeKeys.TRAIN, tf.bool), lambda:source_labels, lambda:labels)\n",
    "            onehot_labels = tf.one_hot(indices=tf.cast(classify_labels, tf.int32), depth=NUM_CLASSES)\n",
    "            label_loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=label_logits)\n",
    "            loss = label_loss\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        with tf.name_scope('domain_loss'):\n",
    "            domain_labels = tf.constant([i%2 for i in range(BATCH_SIZE)], tf.int32)\n",
    "            onehot_domain_labels = tf.one_hot(indices=tf.cast(domain_labels, tf.int32), depth=NUM_DOMAINES)\n",
    "            domain_loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_domain_labels, logits=domain_logits)\n",
    "        with tf.name_scope('total_loss'):\n",
    "            loss = label_loss + domain_loss\n",
    "            tf.summary.scalar(\"label_losss\", label_loss)\n",
    "            tf.summary.scalar(\"domain_loss\", domain_loss)\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=label_loss + domain_loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            optimizer=OPTIMIZER)\n",
    "\n",
    "    with tf.name_scope('predictions'):\n",
    "        # Generate Predictions\n",
    "        predictions = {\n",
    "          \"classes\": tf.argmax(\n",
    "              input=label_logits, axis=1),\n",
    "          \"probabilities\": tf.nn.softmax(\n",
    "              label_logits, name=\"softmax_tensor\")\n",
    "        } \n",
    "\n",
    "    # Return a ModelFnOps object\n",
    "    return model_fn_lib.ModelFnOps(mode=mode, predictions=predictions, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_input_fn(images, labels, batch_size=32, training=True, num_epochs=1):  \n",
    "    with tf.name_scope('input_batch'):\n",
    "        # create input queues\n",
    "        input_queue = tf.train.slice_input_producer(\n",
    "                            [images, labels],\n",
    "                            num_epochs=num_epochs,\n",
    "                            shuffle=True)\n",
    "\n",
    "        image, label = read_images(input_queue)\n",
    "\n",
    "        # preprocess image\n",
    "        image = pre_process_image(tf.to_float(image), training)\n",
    "\n",
    "        # create batch\n",
    "        batch_dict = tf.train.batch(dict(images=image, labels=label) , batch_size,\n",
    "                                    num_threads=1, capacity=batch_size*2, \n",
    "                                    enqueue_many=False, shapes=None, dynamic_pad=False, \n",
    "                                    allow_smaller_final_batch=False, \n",
    "                                    shared_name=None, name=None)\n",
    "\n",
    "        batch_labels = batch_dict.pop('labels')\n",
    "        return batch_dict, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_input_train_fn(source_images, source_labels, target_images, target_labels, batch_size=64, training=True, num_epochs=1):  \n",
    "    with tf.name_scope('input_batch'):\n",
    "        # create input queues\n",
    "        input_source_queue = tf.train.slice_input_producer(\n",
    "                            [source_images, source_labels],\n",
    "                            num_epochs=num_epochs,\n",
    "                            shuffle=True,\n",
    "                            name='synthetic_image')\n",
    "\n",
    "        input_target_queue = tf.train.slice_input_producer(\n",
    "                            [target_images, target_labels],\n",
    "                            num_epochs=num_epochs,\n",
    "                            shuffle=True,\n",
    "                            name='real_image')\n",
    "\n",
    "        source_image, source_label = read_images(input_source_queue)\n",
    "        target_image, target_label = read_images(input_target_queue)\n",
    "\n",
    "        # preprocess image\n",
    "        source_image = pre_process_image(tf.to_float(source_image), training)\n",
    "        target_image = pre_process_image(tf.to_float(target_image), training)\n",
    "        # create batch\n",
    "        batch_dict = tf.train.batch(dict(images=[source_image, target_image], labels=[source_label, target_label]) , batch_size,\n",
    "                                    num_threads=1, capacity=batch_size*2, \n",
    "                                    enqueue_many=True, shapes=None, dynamic_pad=False, \n",
    "                                    allow_smaller_final_batch=False, \n",
    "                                    shared_name=None, name=None)\n",
    "    \n",
    "    batch_labels = batch_dict.pop('labels')\n",
    "    return batch_dict, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the Estimator\n",
    "toppad_classifier = learn.Estimator(model_fn=cnn_model_vgg_fn, model_dir=\"toppad_classifier/{}_vgg16_{}_lr{}_lb{}\".format(MODEL_NAME, OPTIMIZER, LEARNING_RATE, LAMBDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Configure validation and test hooks\n",
    "toppad_validator = learn.monitors.ValidationMonitor(\n",
    "      input_fn=lambda: batch_input_fn(val_images, val_labels, batch_size=BATCH_SIZE, training=False),\n",
    "      every_n_steps=STEPS_PER_EPOCH,\n",
    "      metrics={\"accuracy_synthetic\": learn.MetricSpec(metric_fn=tf.metrics.accuracy, prediction_key=\"classes\"),},)\n",
    "\n",
    "toppad_tester = learn.monitors.ValidationMonitor(\n",
    "      input_fn=lambda: batch_input_fn(test_images, test_labels, batch_size=BATCH_SIZE, training=False),\n",
    "      every_n_steps=STEPS_PER_EPOCH,\n",
    "      metrics={\"accuracy_real\": learn.MetricSpec(metric_fn=tf.metrics.accuracy, prediction_key=\"classes\"),},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs  = 999\n",
    "toppad_classifier.fit(\n",
    "  input_fn=lambda: batch_input_train_fn(source_images, source_labels, target_images, target_labels, \n",
    "  batch_size=BATCH_SIZE, training=True, num_epochs=num_epochs),\n",
    "  monitors=[toppad_validator, toppad_tester])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
